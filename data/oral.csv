abstract,authors,keywords,submission_date,title,tldr,type,url
"One of the challenges in the study of generative adversarial networks is the instability of its training. 
        In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator.
        Our new normalization technique is computationally light and easy to incorporate into existing implementations. 
        We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. ",['Takeru Miyato · Toshiki Kataoka · Masanori Koyama · Yuichi Yoshida'],"Generative Adversarial Networks, Deep Generative Models, Unsupervised Learning","Feb 15, 2018 (modified: Feb 16, 2018)",['Spectral Normalization for Generative Adversarial Networks'],We propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.,Oral,https://openreview.net/forum?id=B1QRgziT-
"Generative models provide a way to model structure in complex distributions and have been shown to be useful for many tasks of practical interest. However, current techniques for training generative models require access to fully-observed samples. In many settings, it is expensive or even impossible to obtain fully-observed samples, but economical to obtain partial, noisy observations. We consider the task of learning an implicit generative model given only lossy measurements of samples from the distribution of interest. We show that the true underlying distribution can be provably recovered even in the presence of per-sample information loss for a class of measurement models. Based on this, we propose a new method of training Generative Adversarial Networks (GANs) which we call AmbientGAN. On three benchmark datasets, and for various measurement models, we demonstrate substantial qualitative and quantitative improvements. Generative models trained with our method can obtain $2$-$4$x higher inception scores than the baselines.",['Ashish Bora · Eric Price · Alexandros Dimakis'],"Generative models, Adversarial networks, Lossy measurements","Feb 15, 2018 (modified: Feb 23, 2018)",['AmbientGAN: Generative models from lossy measurements'],"How to learn GANs from noisy, distorted, partial observations",Oral,https://openreview.net/forum?id=Hy7fDog0b
"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.",['Tero Karras · Timo Aila · Samuli   Laine · Jaakko Lehtinen'],"generative adversarial networks, unsupervised learning, hierarchical methods","Feb 15, 2018 (modified: Feb 23, 2018)","['Progressive Growing of GANs for Improved Quality, Stability, and Variation']","We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.",Oral,https://openreview.net/forum?id=Hk99zCeAb
"We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE).
        This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE). Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality.",['Ilya Tolstikhin · Olivier Bousquet · Sylvain Gelly · Bernhard   Schoelkopf'],"auto-encoder, generative models, GAN, VAE, unsupervised learning","Feb 15, 2018 (modified: Feb 20, 2018)",['Wasserstein Auto-Encoders'],"We propose a new auto-encoder based on the Wasserstein distance, which improves on the sampling properties of VAE.",Oral,https://openreview.net/forum?id=HkL7n1-0b
" Several recently proposed stochastic optimization methods that have been successfully used in training deep networks such as RMSProp, Adam, Adadelta, Nadam are based on using gradient updates scaled by square roots of exponential moving averages of squared past gradients. In many applications, e.g. learning with large output spaces, it has been empirically observed that these algorithms fail to converge to an optimal solution (or a critical point in nonconvex settings). We show that one cause for such failures is the exponential moving average used in the algorithms. We provide an explicit example of a simple convex optimization setting where Adam does not converge to the optimal solution, and describe the precise problems with the previous analysis of Adam algorithm. Our analysis suggests that the convergence issues can be fixed by endowing such algorithms with ``long-term memory'' of past gradients, and propose new variants of the Adam algorithm which not only fix the convergence issues but often also lead to improved empirical performance.",['Sashank Reddi · Satyen Kale · Sanjiv Kumar'],"optimization, deep learning, adam, rmsprop","Feb 15, 2018 (modified: Mar 27, 2018)",['On the Convergence of Adam and Beyond'],"We investigate the convergence of popular optimization algorithms like Adam , RMSProp and propose new variants of these methods which provably converge to optimal solution in convex  settings. ",Oral,https://openreview.net/forum?id=ryQu7f-RZ
"Momentum based stochastic gradient methods such as heavy ball (HB) and Nesterov's accelerated gradient descent (NAG) method are widely used in practice for training deep networks and other supervised learning models, as they often provide significant improvements over stochastic gradient descent (SGD). Rigorously speaking, fast gradient methods have provable improvements over gradient descent only for the deterministic case, where the gradients are exact. In the stochastic case, the popular explanations for their wide applicability is that when these fast gradient methods are applied in the stochastic case, they partially mimic their exact gradient counterparts, resulting in some practical gain. This work provides a counterpoint to this belief by proving that there exist simple problem instances where these methods cannot outperform SGD despite the best setting of its parameters. These negative problem instances are, in an informal sense, generic; they do not look like carefully constructed pathological instances. These results suggest (along with empirical evidence) that HB or NAG's practical performance gains are a by-product of minibatching.
        
        Furthermore, this work provides a viable (and provable) alternative, which, on the same set of problem instances, significantly improves over HB, NAG, and SGD's performance. This algorithm, referred to as Accelerated Stochastic Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based on a relatively less popular variant of Nesterov's Acceleration. Extensive empirical results in this paper show that ASGD has performance gains over HB, NAG, and SGD. The code for implementing the ASGD Algorithm can be found at https://github.com/rahulkidambi/AccSGD.
        ",['Rahul Kidambi · Praneeth Netrapalli · Prateek   Jain · Sham M Kakade'],"Stochastic Gradient Descent, Deep Learning, Momentum, Acceleration, Heavy Ball, Nesterov Acceleration, Stochastic Optimization, SGD, Accelerated Stochastic Gradient Descent","Feb 15, 2018 (modified: Feb 23, 2018)",['On the insufficiency of existing momentum schemes for Stochastic Optimization'],"Existing momentum/acceleration schemes such as heavy ball method and Nesterov's acceleration employed with stochastic gradients do not improve over vanilla stochastic gradient descent, especially when employed with small batch sizes.",Oral,https://openreview.net/forum?id=rJTutzbA-
"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.
        
        In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.",['Miltiadis Allamanis · Marc Brockschmidt · Mahmoud Khademi'],"programs, source code, graph neural networks","Feb 15, 2018 (modified: Feb 22, 2018)",['Learning to Represent Programs with Graphs'],"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs",Oral,https://openreview.net/forum?id=BJOFETxR-
"We study the problem of generating source code in a strongly typed,
        Java-like programming language, given a label (for example a set of
        API calls or types) carrying a small amount of information about the
        code that is desired. The generated programs are expected to respect a
        `""realistic"" relationship between programs and labels, as exemplified
        by a corpus of labeled programs available during training.
        
        Two challenges in such *conditional program generation* are that
        the generated programs must satisfy a rich set of syntactic and
        semantic constraints, and that source code contains many low-level
        features that impede learning.  We address these problems by training
        a neural generator not on code but on *program sketches*, or
        models of program syntax that abstract out names and operations that
        do not generalize across programs. During generation, we infer a
        posterior distribution over sketches, then concretize samples from
        this distribution into type-safe programs using combinatorial
        techniques.  We implement our ideas in a system for generating
        API-heavy Java code, and show that it can often predict the entire
        body of a method given just a few API calls or data types that appear
        in the method.",['Vijayaraghavan Murali · Letao Qi · Swarat Chaudhuri · Chris   Jermaine'],"Program generation, Source code, Program synthesis, Deep generative models","Feb 15, 2018 (modified: Feb 24, 2018)",['Neural Sketch Learning for Conditional Program Generation'],"We give a method for generating type-safe programs in a Java-like language, given a small amount of syntactic information about the desired code.",Oral,https://openreview.net/forum?id=HkfXMz-Ab
"Deep Neural Networks (DNNs) have recently been shown to be vulnerable against adversarial examples, which are carefully crafted instances that can mislead DNNs to make errors during prediction. To better understand such attacks, a characterization is needed of the properties of regions (the so-called `adversarial subspaces') in which adversarial examples lie. We tackle this challenge by characterizing the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID). LID assesses the space-filling capability of the region surrounding a reference example, based on the distance distribution of the example to its neighbors. We first provide explanations about how adversarial perturbation can affect the LID characteristic of adversarial regions, and then show empirically that LID characteristics can facilitate the distinction of adversarial examples generated using state-of-the-art attacks. As a proof-of-concept, we show that a potential application of LID is to distinguish adversarial examples, and the preliminary results show that it can outperform several state-of-the-art detection measures by large margins for five attack strategies considered in this paper across three benchmark datasets. Our analysis of the LID characteristic for adversarial regions not only motivates new directions of effective adversarial defense, but also opens up more challenges for developing new attacks to better understand the vulnerabilities of DNNs.",['Xingjun Ma · Bo Li · Yisen Wang · Sarah Erfani · Sudanthi Wijewickrema · Grant Schoenebeck · dawn song · Michael E Houle · James Bailey'],"Adversarial Subspace, Local Intrinsic Dimensionality, Deep Neural Networks","Feb 15, 2018 (modified: Mar 23, 2018)",['Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality'],We characterize the dimensional properties of adversarial subspaces in the neighborhood of adversarial examples via the use of Local Intrinsic Dimensionality (LID).,Oral,https://openreview.net/forum?id=B1gJ1L2aW
"Neural networks are vulnerable to adversarial examples and researchers have proposed many heuristic attack and defense mechanisms. We address this problem through the principled lens of distributionally robust optimization, which guarantees performance under adversarial input perturbations.  By considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball, we provide a training procedure that augments model parameter updates with worst-case perturbations of training data. For smooth losses, our procedure provably achieves moderate levels of robustness with little computational or statistical cost relative to empirical risk minimization. Furthermore, our statistical guarantees allow us to efficiently certify robustness for the population loss. For imperceptible perturbations, our method matches or outperforms heuristic approaches.
        ",['Aman Sinha · Hong Namkoong · John   Duchi'],"adversarial training, distributionally robust optimization, deep learning, optimization, learning theory","Feb 15, 2018 (modified: Feb 24, 2018)",['Certifying Some Distributional Robustness with Principled Adversarial Training'],"We provide a fast, principled adversarial training procedure with computational and statistical performance guarantees.",Oral,https://openreview.net/forum?id=Hk6kPgZA-
"The driving force behind deep networks is their ability to compactly represent rich classes of functions. The primary notion for formally reasoning about this phenomenon is expressive efficiency, which refers to a situation where one network must grow unfeasibly large in order to replicate functions of another. To date, expressive efficiency analyses focused on the architectural feature of depth, showing that deep networks are representationally superior to shallow ones. In this paper we study the expressive efficiency brought forth by connectivity, motivated by the observation that modern networks interconnect their layers in elaborate ways. We focus on dilated convolutional networks, a family of deep models delivering state of the art performance in sequence processing tasks. By introducing and analyzing the concept of mixed tensor decompositions, we prove that interconnecting dilated convolutional networks can lead to expressive efficiency. In particular, we show that even a single connection between intermediate layers can already lead to an almost quadratic gap, which in large-scale settings typically makes the difference between a model that is practical and one that is not. Empirical evaluation demonstrates how the expressive efficiency of connectivity, similarly to that of depth, translates into gains in accuracy. This leads us to believe that expressive efficiency may serve a key role in developing new tools for deep network design.",['Nadav Cohen · Ronen Tamari · Amnon Shashua'],"Deep Learning, Expressive Efficiency, Dilated Convolutions, Tensor Decompositions","Feb 15, 2018 (modified: Feb 15, 2018)",['Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions'],"We introduce the notion of mixed tensor decompositions, and use it to prove that interconnecting dilated convolutional networks boosts their expressive power.",Oral,https://openreview.net/forum?id=S1JHhv6TW
"Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective.
        
        In this paper we introduce the building blocks for constructing spherical CNNs. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical CNNs applied to 3D model recognition and atomization energy regression.",['Taco Cohen · Mario Geiger · Jonas Koehler · Max Welling'],"deep learning, equivariance, convolution, group convolution, 3D, vision, omnidirectional, shape recognition, molecular energy regression","Feb 15, 2018 (modified: Feb 25, 2018)",['Spherical CNNs'],"We introduce Spherical CNNs, a convolutional network for spherical signals, and apply it to 3D model recognition and molecular energy regression.",Oral,https://openreview.net/forum?id=Hkbd5xZRb
"The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both 'what' and 'how' to imitate. We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss. In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference. The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task. Our method is 'zero-shot' in the sense that the agent never has access to expert actions during training or for the task demonstration at inference. We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot. Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance. Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/.",['Deepak Pathak · Parsa Mahmoudieh · Guanghao Luo · Pulkit Agrawal · Dian Chen · Fred   Shentu · Evan Shelhamer · Jitendra Malik · Alexei Efros · Trevor Darrell'],"imitation, zero-shot, self-supervised, robotics, skills, navigation, manipulation, vizdoom, reinforcement","Feb 15, 2018 (modified: Apr 20, 2018)",['Zero-Shot Visual Imitation'],Agents can learn to imitate solely visual demonstrations (without actions) at test time after learning from their own experience without any form of supervision at training time.,Oral,https://openreview.net/forum?id=BkisuzWRW
"In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network’s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across “easier” and “harder” inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.",['Gao Huang · Danlu Chen · Tianhong Li · Felix   Wu · Laurens van der Maaten · Kilian Q Weinberger'],"efficient learning, budgeted learning, deep learning, image classification, convolutional networks","Feb 15, 2018 (modified: Feb 23, 2018)",['Multi-Scale Dense Networks for Resource Efficient Image Classification'],,Oral,https://openreview.net/forum?id=Hk2aImxAb
"Researches on deep neural networks with discrete parameters and their deployment in embedded systems have been active and promising topics. Although previous works have successfully reduced precision in inference, transferring both training and inference processes to low-bitwidth integers has not been demonstrated simultaneously. In this work, we develop a new method termed as ``""WAGE"" to discretize both training and inference, where weights (W), activations (A), gradients (G) and errors (E) among layers are shifted and linearly constrained to low-bitwidth integers. To perform pure discrete dataflow for fixed-point devices, we further replace batch normalization by a constant scaling layer and simplify other components that are arduous for integer implementation. Improved accuracies can be obtained on multiple datasets, which indicates that WAGE somehow acts as a type of regularization. Empirically, we demonstrate the potential to deploy training in hardware systems such as integer-based deep learning accelerators and neuromorphic chips with comparable accuracy and higher energy efficiency, which is crucial to future AI applications in variable scenarios with transfer and continual learning demands.",['Shuang Wu · Guoqi Li · Feng Chen · Luping Shi'],"quantization, training, bitwidth, ternary weights","Feb 15, 2018 (modified: Feb 15, 2018)",['Training and Inference with Integers in Deep Neural Networks'],We apply training and inference with only low-bitwidth integers in DNNs,Oral,https://openreview.net/forum?id=HJGXzmspb
"We frame Question Answering (QA) as a Reinforcement Learning task, an approach that we call Active Question Answering. 
        
        We propose an agent that sits between the user and a black box QA system and learns to reformulate questions to elicit the best possible answers. The agent probes the system with, potentially many, natural language reformulations of an initial question and aggregates the returned evidence to yield the best answer. 
        
        The reformulation system is trained end-to-end to maximize answer quality using policy gradient. We evaluate on SearchQA, a dataset of complex questions extracted from Jeopardy!. The agent outperforms a state-of-the-art base model, playing the role of the environment, and other benchmarks.
        
        We also analyze the language that the agent has learned while interacting with the question answering system. We find that successful question reformulations look quite different from natural language paraphrases. The agent is able to discover non-trivial reformulation strategies that resemble classic information retrieval techniques such as term re-weighting (tf-idf) and stemming.",['Christian   Buck · Jannis Bulian · Massimiliano Ciaramita · Wojciech Gajewski · Andrea   Gesmundo · Neil Houlsby · Wei   Wang.'],"machine translation, paraphrasing, question answering, reinforcement learning, agents","Feb 15, 2018 (modified: Feb 23, 2018)",['Ask the Right Questions: Active Question Reformulation with Reinforcement Learning'],We propose an agent that sits between the user and a black box question-answering system and which learns to reformulate questions to elicit the best possible answers,Oral,https://openreview.net/forum?id=S1CChZ-CZ
"The ability of algorithms to evolve or learn (compositional) communication protocols has traditionally been studied in the language evolution literature through the use of emergent communication tasks. Here we scale up this research by using contemporary deep learning methods and by training reinforcement-learning neural network agents on referential communication games. We extend previous work, in which agents were trained in symbolic environments, by developing agents which are able to learn from raw pixel data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ",['Angeliki Lazaridou · Karl M Hermann · Karl Tuyls · Stephen Clark'],"disentanglement, communication, emergent language, compositionality, multi-agent","Feb 15, 2018 (modified: Feb 24, 2018)",['Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input'],A controlled study of the role of environments with respect to properties in emergent communication protocols.,Oral,https://openreview.net/forum?id=HJGv1Z-AW
"We consider the problem of representing collective behavior of large populations and predicting the evolution of a population distribution over a discrete state space. A discrete time mean field game (MFG) is motivated as an interpretable model founded on game theory for understanding the aggregate effect of individual actions and predicting the temporal evolution of population distributions. We achieve a synthesis of MFG and Markov decision processes (MDP) by showing that a special MFG is reducible to an MDP. This enables us to broaden the scope of mean field game theory and infer MFG models of large real-world systems via deep inverse reinforcement learning. Our method learns both the reward function and forward dynamics of an MFG from real data, and we report the first empirical test of a mean field game model of a real-world social media population.",['Jiachen Yang · Xiaojing Ye · Rakshit Trivedi · huan   xu · Hongyuan Zha'],"mean field games, reinforcement learning, Markov decision processes, inverse reinforcement learning, deep learning, inverse optimal control, computational social science, population modeling","Feb 15, 2018 (modified: Feb 23, 2018)",['Learning Deep Mean Field Games for Modeling Large Population Behavior'],Inference of a mean field game (MFG) model of large population behavior via a synthesis of MFG and Markov decision processes.,Oral,https://openreview.net/forum?id=HktK4BeCZ
"Policy gradient methods have enjoyed great success in deep reinforcement learning but suffer from high variance of gradient estimates. The high variance problem is particularly exasperated in problems with long horizons or high-dimensional action spaces. To mitigate this issue, we derive a bias-free action-dependent baseline for variance reduction which fully exploits the structural form of the stochastic policy itself and does not make any additional assumptions about the MDP. We demonstrate and quantify the benefit of the action-dependent baseline through both theoretical analysis as well as numerical results, including an analysis of the suboptimality of the optimal state-dependent baseline. The result is a computationally efficient policy gradient algorithm, which scales to high-dimensional control problems, as demonstrated by a synthetic 2000-dimensional target matching task. Our experimental results indicate that action-dependent baselines allow for faster learning on standard reinforcement learning benchmarks and high-dimensional hand manipulation and synthetic tasks. Finally, we show that the general idea of including additional information in baselines for improved variance reduction can be extended to partially observed and multi-agent tasks.",['Cathy Wu · Aravind Rajeswaran · Yan   Duan · Vikash   Kumar · Alexandre M Bayen · Sham M Kakade · Igor   Mordatch · Pieter Abbeel'],"reinforcement learning, policy gradient, variance reduction, baseline, control variates","Feb 15, 2018 (modified: Feb 25, 2018)",['Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines'],Action-dependent baselines can be bias-free and yield greater variance reduction than state-only dependent baselines for policy gradient methods.,Oral,https://openreview.net/forum?id=H1tSsb-AW
"Ability to continuously learn and adapt from limited experience in nonstationary environments is an important milestone on the path towards general intelligence. In this paper, we cast the problem of continuous adaptation into the learning-to-learn framework. We develop a simple gradient-based meta-learning algorithm suitable for adaptation in dynamically changing and adversarial scenarios. Additionally, we design a new multi-agent competitive environment, RoboSumo, and define iterated adaptation games for testing various aspects of continuous adaptation. We demonstrate that meta-learning enables significantly more efficient adaptation than reactive baselines in the few-shot regime. Our experiments with a population of agents that learn and compete suggest that meta-learners are the fittest.",['Maruan Al-Shedivat · Trapit Bansal · Yuri Burda · Ilya Sutskever · Igor Mordatch · Pieter Abbeel'],"reinforcement learning, nonstationarity, meta-learning, transfer learning, multi-agent","Feb 15, 2018 (modified: Feb 23, 2018)",['Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments'],,Oral,https://openreview.net/forum?id=Sk2u1g-0-
"Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems.  Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise. ",['Yonatan Belinkov · Yonatan Bisk'],"neural machine translation, characters, noise, adversarial examples, robust training","Feb 15, 2018 (modified: Feb 24, 2018)",['Synthetic and Natural Noise Both Break Neural Machine Translation'],CharNMT is brittle,Oral,https://openreview.net/forum?id=BJ8vJebC-
"The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to LSTMs being characterized as black boxes. To this end, we introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. On the task of sentiment analysis with the Yelp and SST data sets, we show that CD is able to reliably identify words and phrases of contrasting sentiment, and how they are combined to yield the LSTM's final prediction. Using the phrase-level labels in SST, we also demonstrate that CD is able to successfully extract positive and negative negations from an LSTM, something which has not previously been done.",['William Murdoch · Peter J Liu · Bin   Yu'],"interpretability, LSTM, natural language processing, sentiment analysis, interactions","Feb 15, 2018 (modified: Feb 23, 2018)",['Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs'],"We introduce contextual decompositions, an interpretation algorithm for LSTMs capable of extracting word, phrase and interaction-level importance score",Oral,https://openreview.net/forum?id=rkRwGg-0Z
"We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on the large-scale 1B Word dataset, outperforming the baseline by over 5.6 points in perplexity.",['Zhilin Yang · Zihang   Dai ·   · William W Cohen'],,"Feb 15, 2018 (modified: Mar 02, 2018)",['Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'],,Oral,https://openreview.net/forum?id=HkwZSG-CZ
